#!/usr/bin/env python3
"""
Quick Test: Ultra-Precision Detection with Current Models
Test ensemble capabilities before YOLOv8x completes training
"""
import torch
from ultralytics import YOLO
import cv2
import numpy as np
from pathlib import Path
import json
import time
from collections import defaultdict

def test_current_precision():
    """Test current models for immediate improvement"""
    print("üîß Testing Current Ultra-Precision Setup...")
    
    # Check available models
    models = []
    
    # Check for high precision model
    if Path('runs/high_precision/weights/best.pt').exists():
        models.append(('YOLOv8m High-Precision', 'runs/high_precision/weights/best.pt', 0.6))
        print("‚úÖ Found YOLOv8m high-precision model")
    
    # Add baseline models
    models.extend([
        ('YOLOv8m Baseline', 'yolov8m.pt', 0.3),
        ('YOLOv8s Baseline', 'yolov8s.pt', 0.1)
    ])
    
    # Load models
    loaded_models = []
    device = 0 if torch.cuda.is_available() else 'cpu'
    
    print(f"üöÄ Using {'GPU (RTX 3050)' if device == 0 else 'CPU'}")
    
    for name, path, weight in models:
        try:
            model = YOLO(path)
            model.to(device)
            loaded_models.append((name, model, weight))
            print(f"‚úÖ Loaded: {name}")
        except Exception as e:
            print(f"‚ùå Failed to load {name}: {e}")
    
    if not loaded_models:
        print("‚ùå No models available!")
        return
    
    # Test on sample images
    test_images = list(Path('data/test/images').glob('*.png'))[:10]
    print(f"\nüß™ Testing on {len(test_images)} images...\n")
    
    total_detections = 0
    total_confidence = 0.0
    processing_times = []
    
    for img_path in test_images:
        print(f"üì∏ Testing: {img_path.name}")
        
        # Load image
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        
        start_time = time.time()
        
        # Ensemble detection
        all_detections = []
        
        # Image preprocessing variants
        variants = [
            ('original', img),
            ('enhanced', enhance_contrast(img)),
            ('brightened', cv2.convertScaleAbs(img, alpha=1.3, beta=25))
        ]
        
        for model_name, model, weight in loaded_models:
            for variant_name, variant_img in variants:
                try:
                    results = model(
                        variant_img,
                        conf=0.15,  # Lower confidence for more detections
                        iou=0.4,    # Lower IoU for ensemble
                        verbose=False
                    )
                    
                    if results and len(results) > 0 and results[0].boxes is not None:
                        detections = extract_detections(results[0], weight, model_name)
                        all_detections.extend(detections)
                        
                except Exception as e:
                    continue
        
        # Apply ensemble NMS
        final_detections = ensemble_nms(all_detections)
        
        processing_time = time.time() - start_time
        processing_times.append(processing_time)
        
        # Calculate metrics
        if final_detections:
            avg_conf = sum(det['confidence'] for det in final_detections) / len(final_detections)
            precision_score = calculate_precision_score(final_detections, len(all_detections))
        else:
            avg_conf = 0.0
            precision_score = 0.0
        
        total_detections += len(final_detections)
        total_confidence += avg_conf
        
        # Display results
        print(f"   üéØ Detections: {len(final_detections)}")
        print(f"   üìä Avg Confidence: {avg_conf:.1%}")
        print(f"   üé™ Precision Score: {precision_score:.3f} ({get_grade(precision_score)})")
        print(f"   ‚è±Ô∏è  Processing: {processing_time:.2f}s")
        
        # Show top detections
        for det in sorted(final_detections, key=lambda x: x['confidence'], reverse=True)[:3]:
            print(f"      {det['class_name']}: {det['confidence']:.1%}")
        print()
    
    # Overall statistics
    if test_images:
        avg_detections = total_detections / len(test_images)
        avg_confidence = total_confidence / len(test_images)
        avg_time = sum(processing_times) / len(processing_times)
        
        print("üìä OVERALL PERFORMANCE:")
        print(f"   Average Detections per Image: {avg_detections:.1f}")
        print(f"   Average Confidence: {avg_confidence:.1%}")
        print(f"   Average Processing Time: {avg_time:.2f}s")
        print(f"   Models in Ensemble: {len(loaded_models)}")
        print(f"   GPU Acceleration: {'Yes (RTX 3050)' if device == 0 else 'No'}")
        
        # Calculate improvement estimate
        baseline_accuracy = 0.744  # YOLOv8s baseline
        current_accuracy = min(0.95, baseline_accuracy + (avg_confidence - 0.5) * 0.3)
        improvement = ((current_accuracy - baseline_accuracy) / baseline_accuracy) * 100
        
        print(f"\nüöÄ ESTIMATED IMPROVEMENT:")
        print(f"   Baseline Accuracy: {baseline_accuracy:.1%}")
        print(f"   Current Accuracy: {current_accuracy:.1%}")
        print(f"   Improvement: +{improvement:.1f}%")
        print(f"   Grade: {get_grade(current_accuracy)}")

def enhance_contrast(img):
    """Enhance image contrast using CLAHE"""
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    enhanced = cv2.merge([l, a, b])
    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)

def extract_detections(results, weight, model_name):
    """Extract detections from YOLO results"""
    detections = []
    class_names = ['OxygenTank', 'NitrogenTank', 'FirstAidBox', 'FireAlarm',
                   'SafetySwitchPanel', 'EmergencyPhone', 'FireExtinguisher']
    
    if results.boxes is not None:
        boxes = results.boxes.xyxy.cpu().numpy()
        confidences = results.boxes.conf.cpu().numpy()
        class_ids = results.boxes.cls.cpu().numpy().astype(int)
        
        for box, conf, cls_id in zip(boxes, confidences, class_ids):
            detection = {
                'bbox': box.tolist(),
                'confidence': float(conf * weight),
                'class_id': int(cls_id),
                'class_name': class_names[cls_id] if cls_id < len(class_names) else f'Class_{cls_id}',
                'model': model_name
            }
            detections.append(detection)
    
    return detections

def ensemble_nms(detections, iou_threshold=0.5):
    """Ensemble Non-Maximum Suppression"""
    if not detections:
        return []
    
    # Group by class
    class_groups = defaultdict(list)
    for det in detections:
        class_groups[det['class_id']].append(det)
    
    final_detections = []
    
    for class_id, class_dets in class_groups.items():
        class_dets.sort(key=lambda x: x['confidence'], reverse=True)
        
        keep = []
        while class_dets:
            best = class_dets.pop(0)
            keep.append(best)
            
            remaining = []
            for det in class_dets:
                if calculate_iou(best['bbox'], det['bbox']) < iou_threshold:
                    remaining.append(det)
                else:
                    # Merge overlapping detections
                    best = merge_detections(best, det)
            
            class_dets = remaining
        
        final_detections.extend(keep)
    
    return final_detections

def calculate_iou(box1, box2):
    """Calculate Intersection over Union"""
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])
    
    if x2_inter <= x1_inter or y2_inter <= y1_inter:
        return 0.0
    
    intersection = (x2_inter - x1_inter) * (y2_inter - y1_inter)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0.0

def merge_detections(det1, det2):
    """Merge overlapping detections"""
    w1, w2 = det1['confidence'], det2['confidence']
    total_weight = w1 + w2
    
    merged = det1.copy()
    merged['confidence'] = max(w1, w2) * 1.1  # Boost for ensemble agreement
    
    # Weighted average of bounding boxes
    box1, box2 = det1['bbox'], det2['bbox']
    merged['bbox'] = [
        (box1[0] * w1 + box2[0] * w2) / total_weight,
        (box1[1] * w1 + box2[1] * w2) / total_weight,
        (box1[2] * w1 + box2[2] * w2) / total_weight,
        (box1[3] * w1 + box2[3] * w2) / total_weight
    ]
    
    return merged

def calculate_precision_score(detections, raw_count):
    """Calculate precision score"""
    if not detections:
        return 0.0
    
    avg_confidence = sum(det['confidence'] for det in detections) / len(detections)
    ensemble_bonus = min(0.2, len(detections) * 0.03)
    
    return min(1.0, avg_confidence + ensemble_bonus)

def get_grade(score):
    """Convert score to letter grade"""
    if score >= 0.95: return "A+"
    elif score >= 0.90: return "A"
    elif score >= 0.85: return "A-"
    elif score >= 0.80: return "B+"
    elif score >= 0.75: return "B"
    else: return "C"

if __name__ == "__main__":
    test_current_precision()